{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOC (%)</th>\n",
       "      <th>Elev</th>\n",
       "      <th>VDepth</th>\n",
       "      <th>NDVI_max</th>\n",
       "      <th>NDVI_median</th>\n",
       "      <th>NDVI_sd</th>\n",
       "      <th>manual_ndvi_mean</th>\n",
       "      <th>manual_ndvi_max</th>\n",
       "      <th>manual_ndvi_median</th>\n",
       "      <th>manual_ndvi_sd</th>\n",
       "      <th>manual_evi_mean</th>\n",
       "      <th>manual_evi_max</th>\n",
       "      <th>manual_evi_median</th>\n",
       "      <th>manual_evi_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.88</td>\n",
       "      <td>397.309113</td>\n",
       "      <td>9.705094</td>\n",
       "      <td>0.876076</td>\n",
       "      <td>0.694713</td>\n",
       "      <td>0.164614</td>\n",
       "      <td>0.354806</td>\n",
       "      <td>0.929022</td>\n",
       "      <td>0.318386</td>\n",
       "      <td>0.280607</td>\n",
       "      <td>0.266022</td>\n",
       "      <td>0.915359</td>\n",
       "      <td>0.189094</td>\n",
       "      <td>0.214624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.76</td>\n",
       "      <td>397.207977</td>\n",
       "      <td>10.325721</td>\n",
       "      <td>0.915627</td>\n",
       "      <td>0.613926</td>\n",
       "      <td>0.210947</td>\n",
       "      <td>0.316827</td>\n",
       "      <td>0.914741</td>\n",
       "      <td>0.214498</td>\n",
       "      <td>0.291605</td>\n",
       "      <td>0.238355</td>\n",
       "      <td>0.902060</td>\n",
       "      <td>0.144845</td>\n",
       "      <td>0.250118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.10</td>\n",
       "      <td>397.390015</td>\n",
       "      <td>9.450062</td>\n",
       "      <td>0.927210</td>\n",
       "      <td>0.646960</td>\n",
       "      <td>0.234737</td>\n",
       "      <td>0.313768</td>\n",
       "      <td>0.930468</td>\n",
       "      <td>0.212281</td>\n",
       "      <td>0.295640</td>\n",
       "      <td>0.228614</td>\n",
       "      <td>0.939195</td>\n",
       "      <td>0.143667</td>\n",
       "      <td>0.273847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.70</td>\n",
       "      <td>397.513275</td>\n",
       "      <td>8.735661</td>\n",
       "      <td>0.915750</td>\n",
       "      <td>0.711604</td>\n",
       "      <td>0.183207</td>\n",
       "      <td>0.309941</td>\n",
       "      <td>0.939046</td>\n",
       "      <td>0.215351</td>\n",
       "      <td>0.290152</td>\n",
       "      <td>0.232511</td>\n",
       "      <td>1.023655</td>\n",
       "      <td>0.143303</td>\n",
       "      <td>0.276320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.11</td>\n",
       "      <td>397.637207</td>\n",
       "      <td>8.526403</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>0.651558</td>\n",
       "      <td>0.271645</td>\n",
       "      <td>0.319408</td>\n",
       "      <td>0.939321</td>\n",
       "      <td>0.211714</td>\n",
       "      <td>0.299130</td>\n",
       "      <td>-0.040025</td>\n",
       "      <td>0.993927</td>\n",
       "      <td>0.143450</td>\n",
       "      <td>2.141298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>1.63</td>\n",
       "      <td>405.551361</td>\n",
       "      <td>1.685164</td>\n",
       "      <td>0.946501</td>\n",
       "      <td>0.601615</td>\n",
       "      <td>0.312782</td>\n",
       "      <td>0.304213</td>\n",
       "      <td>0.937451</td>\n",
       "      <td>0.205254</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>0.245128</td>\n",
       "      <td>1.247704</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>0.316092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1.62</td>\n",
       "      <td>405.171936</td>\n",
       "      <td>1.950791</td>\n",
       "      <td>0.946501</td>\n",
       "      <td>0.601615</td>\n",
       "      <td>0.312782</td>\n",
       "      <td>0.304213</td>\n",
       "      <td>0.937451</td>\n",
       "      <td>0.205254</td>\n",
       "      <td>0.297226</td>\n",
       "      <td>0.245128</td>\n",
       "      <td>1.247704</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>0.316092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>2.33</td>\n",
       "      <td>406.557678</td>\n",
       "      <td>1.151467</td>\n",
       "      <td>0.947470</td>\n",
       "      <td>0.568452</td>\n",
       "      <td>0.311198</td>\n",
       "      <td>0.326940</td>\n",
       "      <td>0.938113</td>\n",
       "      <td>0.214234</td>\n",
       "      <td>0.310638</td>\n",
       "      <td>0.243626</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.132486</td>\n",
       "      <td>0.302022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>2.98</td>\n",
       "      <td>407.262115</td>\n",
       "      <td>0.967014</td>\n",
       "      <td>0.947902</td>\n",
       "      <td>0.615135</td>\n",
       "      <td>0.303823</td>\n",
       "      <td>0.326886</td>\n",
       "      <td>0.935465</td>\n",
       "      <td>0.218116</td>\n",
       "      <td>0.313055</td>\n",
       "      <td>0.255417</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.150783</td>\n",
       "      <td>0.310982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>4.38</td>\n",
       "      <td>401.999176</td>\n",
       "      <td>6.465769</td>\n",
       "      <td>0.944295</td>\n",
       "      <td>0.603444</td>\n",
       "      <td>0.304284</td>\n",
       "      <td>0.312205</td>\n",
       "      <td>0.830195</td>\n",
       "      <td>0.296314</td>\n",
       "      <td>0.237326</td>\n",
       "      <td>0.245633</td>\n",
       "      <td>1.281772</td>\n",
       "      <td>0.202257</td>\n",
       "      <td>0.255101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SOC (%)        Elev     VDepth  NDVI_max  NDVI_median   NDVI_sd  \\\n",
       "0       4.88  397.309113   9.705094  0.876076     0.694713  0.164614   \n",
       "1       4.76  397.207977  10.325721  0.915627     0.613926  0.210947   \n",
       "2       5.10  397.390015   9.450062  0.927210     0.646960  0.234737   \n",
       "3       5.70  397.513275   8.735661  0.915750     0.711604  0.183207   \n",
       "4       5.11  397.637207   8.526403  0.934996     0.651558  0.271645   \n",
       "..       ...         ...        ...       ...          ...       ...   \n",
       "835     1.63  405.551361   1.685164  0.946501     0.601615  0.312782   \n",
       "836     1.62  405.171936   1.950791  0.946501     0.601615  0.312782   \n",
       "837     2.33  406.557678   1.151467  0.947470     0.568452  0.311198   \n",
       "838     2.98  407.262115   0.967014  0.947902     0.615135  0.303823   \n",
       "839     4.38  401.999176   6.465769  0.944295     0.603444  0.304284   \n",
       "\n",
       "     manual_ndvi_mean  manual_ndvi_max  manual_ndvi_median  manual_ndvi_sd  \\\n",
       "0            0.354806         0.929022            0.318386        0.280607   \n",
       "1            0.316827         0.914741            0.214498        0.291605   \n",
       "2            0.313768         0.930468            0.212281        0.295640   \n",
       "3            0.309941         0.939046            0.215351        0.290152   \n",
       "4            0.319408         0.939321            0.211714        0.299130   \n",
       "..                ...              ...                 ...             ...   \n",
       "835          0.304213         0.937451            0.205254        0.297226   \n",
       "836          0.304213         0.937451            0.205254        0.297226   \n",
       "837          0.326940         0.938113            0.214234        0.310638   \n",
       "838          0.326886         0.935465            0.218116        0.313055   \n",
       "839          0.312205         0.830195            0.296314        0.237326   \n",
       "\n",
       "     manual_evi_mean  manual_evi_max  manual_evi_median  manual_evi_sd  \n",
       "0           0.266022        0.915359           0.189094       0.214624  \n",
       "1           0.238355        0.902060           0.144845       0.250118  \n",
       "2           0.228614        0.939195           0.143667       0.273847  \n",
       "3           0.232511        1.023655           0.143303       0.276320  \n",
       "4          -0.040025        0.993927           0.143450       2.141298  \n",
       "..               ...             ...                ...            ...  \n",
       "835         0.245128        1.247704           0.132829       0.316092  \n",
       "836         0.245128        1.247704           0.132829       0.316092  \n",
       "837         0.243626        0.982609           0.132486       0.302022  \n",
       "838         0.255417        0.987434           0.150783       0.310982  \n",
       "839         0.245633        1.281772           0.202257       0.255101  \n",
       "\n",
       "[840 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('./data/ds_canada/dataset.csv')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = np.array(dataset['SOC (%)'])\n",
    "features = np.array(dataset.drop('SOC (%)', axis = 1))\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         keras.layers.Dense(512, activation=\"relu\"),\n",
    "#         keras.layers.Dense(1024, activation=\"relu\"),\n",
    "#         keras.layers.Dense(2048, activation=\"relu\"),\n",
    "#         keras.layers.Dense(1024, activation=\"relu\"),\n",
    "#         keras.layers.Dense(512, activation=\"relu\"),\n",
    "#         keras.layers.Dense(1)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# model.compile(loss='mean_absolute_error', optimizer = 'adam')\n",
    "\n",
    "# history = model.fit(train_features, train_labels, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Error of our Model is 0.51\n",
      "The accuracy of our model is 50.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "predictions = model.predict(test_features)\n",
    "\n",
    "score = mean_absolute_error(test_labels, predictions)\n",
    "print(\"The Mean Absolute Error of our Model is {}\".format(round(score, 2)))\n",
    "\n",
    "score = r2_score(test_labels, predictions)\n",
    "print(\"The accuracy of our model is {}%\".format(round(score, 2) *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: VDepth               Importance: 0.34\n",
      "Variable: NDVI_sd              Importance: 0.12\n",
      "Variable: Elev                 Importance: 0.11\n",
      "Variable: NDVI_median          Importance: 0.06\n",
      "Variable: manual_ndvi_median   Importance: 0.05\n",
      "Variable: manual_evi_mean      Importance: 0.05\n",
      "Variable: NDVI_max             Importance: 0.04\n",
      "Variable: manual_ndvi_mean     Importance: 0.04\n",
      "Variable: manual_evi_median    Importance: 0.04\n",
      "Variable: manual_evi_sd        Importance: 0.04\n",
      "Variable: manual_ndvi_max      Importance: 0.03\n",
      "Variable: manual_ndvi_sd       Importance: 0.03\n",
      "Variable: manual_evi_max       Importance: 0.03\n"
     ]
    }
   ],
   "source": [
    "importances = list(model.feature_importances_)\n",
    "\n",
    "feature_list = list(dataset.columns)\n",
    "feature_list.remove('SOC (%)')\n",
    "\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:20} Importance: {}'.format(*pair)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
