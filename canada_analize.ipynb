{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 10:13:00,422] A new study created in memory with name: no-name-94ae3e1a-5353-4de7-91b1-206738acaeed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 10:13:07,690] Trial 0 finished with value: 0.4941189463543847 and parameters: {'n_estimators': 934, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.4941189463543847.\n",
      "[I 2023-11-20 10:13:11,416] Trial 1 finished with value: 0.24620219131899468 and parameters: {'n_estimators': 1191, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.4941189463543847.\n",
      "[I 2023-11-20 10:13:15,315] Trial 2 finished with value: 0.3537250174080141 and parameters: {'n_estimators': 941, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.4941189463543847.\n",
      "[I 2023-11-20 10:13:30,099] Trial 3 finished with value: 0.5047190166438158 and parameters: {'n_estimators': 1732, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.5047190166438158.\n",
      "[I 2023-11-20 10:13:40,602] Trial 4 finished with value: 0.5011338857874601 and parameters: {'n_estimators': 1307, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.5047190166438158.\n",
      "[I 2023-11-20 10:13:52,262] Trial 5 finished with value: 0.49647296970906407 and parameters: {'n_estimators': 1345, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.5047190166438158.\n",
      "[I 2023-11-20 10:14:04,799] Trial 6 finished with value: 0.5056019315014559 and parameters: {'n_estimators': 1367, 'max_depth': 19, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 6 with value: 0.5056019315014559.\n",
      "[I 2023-11-20 10:14:11,644] Trial 7 finished with value: 0.48279093508746884 and parameters: {'n_estimators': 1010, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 6 with value: 0.5056019315014559.\n",
      "[I 2023-11-20 10:14:24,417] Trial 8 finished with value: 0.5170865887266348 and parameters: {'n_estimators': 1270, 'max_depth': 26, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.5170865887266348.\n",
      "[I 2023-11-20 10:14:25,980] Trial 9 finished with value: 0.499836951433155 and parameters: {'n_estimators': 197, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 7}. Best is trial 8 with value: 0.5170865887266348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable: VDepth               Importance: 0.41\n",
      "Variable: ndvi_mean            Importance: 0.19\n",
      "Variable: Elev                 Importance: 0.16\n",
      "Variable: evi_mean             Importance: 0.09\n",
      "Variable: evi2_mean            Importance: 0.06\n",
      "Variable: savi_mean            Importance: 0.04\n",
      "Variable: gndvi_mean           Importance: 0.03\n",
      "Variable: ndwi_mean            Importance: 0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_errors = []\n",
    "rf_metrics = []\n",
    "\n",
    "dataset = pd.read_csv('./data/ds_canada/dataset.csv')\n",
    "\n",
    "labels = np.array(dataset['SOC (%)'])\n",
    "features = np.array(dataset.drop('SOC (%)', axis = 1))\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth,min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=42)\n",
    "    rf_model.fit(train_features, train_labels)\n",
    "\n",
    "    score = rf_model.score(test_features, test_labels)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "rf = RandomForestRegressor(**study.best_params, random_state=42)\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "mae = mean_absolute_error(test_labels, predictions)\n",
    "r2 = r2_score(test_labels, predictions)\n",
    "\n",
    "rf_errors.append(mae)\n",
    "rf_metrics.append(r2)\n",
    "\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "feature_list = list(dataset.columns)\n",
    "feature_list.remove('SOC (%)')\n",
    "\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "print()\n",
    "\n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:20} Importance: {}'.format(*pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 10:17:12,939] A new study created in memory with name: no-name-97d4c643-bdc4-4129-b586-c1216e2880ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-20 10:17:13,284] Trial 0 finished with value: 0.338896633288268 and parameters: {'n_estimators': 871, 'max_depth': 2}. Best is trial 0 with value: 0.338896633288268.\n",
      "[I 2023-11-20 10:17:13,645] Trial 1 finished with value: 0.4445544245778854 and parameters: {'n_estimators': 1074, 'max_depth': 5}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:13,776] Trial 2 finished with value: 0.37738944779906725 and parameters: {'n_estimators': 270, 'max_depth': 3}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:14,526] Trial 3 finished with value: 0.38471409122405875 and parameters: {'n_estimators': 1299, 'max_depth': 19}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:15,213] Trial 4 finished with value: 0.3982287560344 and parameters: {'n_estimators': 907, 'max_depth': 21}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:15,807] Trial 5 finished with value: 0.3744950940232713 and parameters: {'n_estimators': 1582, 'max_depth': 15}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:16,532] Trial 6 finished with value: 0.378110112412377 and parameters: {'n_estimators': 636, 'max_depth': 31}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:17,059] Trial 7 finished with value: 0.37952218559082895 and parameters: {'n_estimators': 1220, 'max_depth': 18}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:17,608] Trial 8 finished with value: 0.3848261835196781 and parameters: {'n_estimators': 219, 'max_depth': 22}. Best is trial 1 with value: 0.4445544245778854.\n",
      "[I 2023-11-20 10:17:18,173] Trial 9 finished with value: 0.38471409122405875 and parameters: {'n_estimators': 1115, 'max_depth': 19}. Best is trial 1 with value: 0.4445544245778854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable: VDepth               Importance: 0.2800000011920929\n",
      "Variable: ndvi_mean            Importance: 0.15000000596046448\n",
      "Variable: evi2_mean            Importance: 0.12999999523162842\n",
      "Variable: Elev                 Importance: 0.10999999940395355\n",
      "Variable: evi_mean             Importance: 0.10000000149011612\n",
      "Variable: gndvi_mean           Importance: 0.07999999821186066\n",
      "Variable: savi_mean            Importance: 0.07999999821186066\n",
      "Variable: ndwi_mean            Importance: 0.05999999865889549\n"
     ]
    }
   ],
   "source": [
    "xgb_errors = []\n",
    "xgb_metrics = []\n",
    "\n",
    "dataset = pd.read_csv('./data/ds_canada/dataset.csv')\n",
    "\n",
    "labels = np.array(dataset['SOC (%)'])\n",
    "features = np.array(dataset.drop('SOC (%)', axis = 1))\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 2000)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "\n",
    "    xgboost = XGBRegressor(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    xgboost.fit(train_features, train_labels)\n",
    "\n",
    "    score = xgboost.score(test_features, test_labels)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "xgboost = XGBRegressor(**study.best_params)\n",
    "xgboost.fit(train_features, train_labels)\n",
    "\n",
    "predictions = xgboost.predict(test_features)\n",
    "\n",
    "mae = mean_absolute_error(test_labels, predictions)\n",
    "r2 = r2_score(test_labels, predictions)\n",
    "\n",
    "xgb_errors.append(mae)\n",
    "xgb_metrics.append(r2)\n",
    "\n",
    "importances = list(xgboost.feature_importances_)\n",
    "\n",
    "feature_list = list(dataset.columns)\n",
    "feature_list.remove('SOC (%)')\n",
    "\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "print()\n",
    "\n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:20} Importance: {}'.format(*pair)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(2017, 2022), rf_errors)\n",
    "# plt.plot(range(2017, 2022), xgb_errors)\n",
    "# plt.legend([\"random forest\", \"xgboost\"], loc =\"lower left\")\n",
    "# plt.title(\"Errors of the models per year\") \n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(2017, 2022), rf_metrics)\n",
    "# plt.plot(range(2017, 2022), xgb_metrics)\n",
    "# plt.legend([\"random forest\", \"xgboost\"], loc =\"lower left\")\n",
    "# plt.title(\"Metrics of the models per year\") \n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
